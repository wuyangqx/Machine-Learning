{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b458cfb9",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c536747",
   "metadata": {},
   "source": [
    "The Netflix Prize was an open competition for the best collaborative filtering algorithm to predict user ratings for films, based on previous ratings without any other information about the users or films. The competition was held by Netflix, an online DVD rental service, and ran from October 2006 to September 2009. The winning team, BellKor's Pragmatic Chaos, received a $1 million prize for their algorithm, which improved the accuracy of Netflix's recommendation system by over 10%.\n",
    "\n",
    "The winning algorithm is a complex one. It combines over 800 predictive features and uses sophisticated blending techniques. It included elements from multiple teams and used various methods such as matrix factorization, temporal dynamics and ensemble methods.  The algorithm did not get adopted by Netflix production system due to its complexity.   Nonetheless, the essential techniques, such as matrix factorization and ensemble method, are fundamental in recommendation system and we will explore them in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545cfd83",
   "metadata": {},
   "source": [
    "## Read and Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a81b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9074f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rating_data(fileDir, fileName):\n",
    "    # load the Netflix data in \n",
    "    df = pd.read_csv(fileDir + fileName, header = None, names = ['Cust_Id', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "\n",
    "    # movie ID\n",
    "    dfM = df[df['Rating'].isna()][['Cust_Id']].copy()\n",
    "    dfM.rename(columns = {'Cust_Id' : 'Movie_Id'}, inplace=True)\n",
    "\n",
    "    dfT = pd.merge(left = df, right = dfM, how = 'left', left_index=True, right_index=True)\n",
    "    dfT['Movie_Id'] = dfT['Movie_Id'].ffill().apply(lambda i: i[:-1])\n",
    "    dfT = dfT[~dfT['Rating'].isna()]\n",
    "\n",
    "    dfT[['Cust_Id', 'Movie_Id']] = dfT[['Cust_Id', 'Movie_Id']].astype(int)\n",
    "    return dfT\n",
    "\n",
    "def load_probe_data(fileDir, fileName):\n",
    "    df = pd.read_csv(fileDir + fileName, header = None, names = ['Cust_Id'], usecols=[0])\n",
    "\n",
    "    isMovie = df['Cust_Id'].str.contains(':')\n",
    "    dfM = df[isMovie].copy()\n",
    "    dfM.rename(columns = {'Cust_Id' : 'Movie_Id'}, inplace=True)\n",
    "\n",
    "    dfT = pd.merge(left = df, right = dfM, how = 'left', left_index=True, right_index=True)\n",
    "    dfT['Movie_Id'] = dfT['Movie_Id'].ffill().apply(lambda i: i[:-1])\n",
    "    dfT = dfT[~isMovie]\n",
    "\n",
    "    dfT[['Cust_Id', 'Movie_Id']] = dfT[['Cust_Id', 'Movie_Id']].astype(int)\n",
    "    return dfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rating dataset\n",
    "df1 = load_rating_data('./netflix-prize-data/', 'combined_data_1.txt')\n",
    "# df2 = load_rating_data('./netflix-prize-data/', 'combined_data_2.txt')\n",
    "# df3 = load_rating_data('./netflix-prize-data/', 'combined_data_3.txt')\n",
    "# df4 = load_rating_data('./netflix-prize-data/', 'combined_data_4.txt')\n",
    "dfRating = pd.concat([df1])   #[df1, df2, df3, df4]\n",
    "\n",
    "# laod the probe dataset, which is a subset of rating dataset.  We mark probe dataset as testing data while the rest as training data\n",
    "dfProbe = load_probe_data('./netflix-prize-data/', 'probe.txt')\n",
    "dfProbe['test'] = True\n",
    "\n",
    "dfRating = pd.merge(dfRating, dfProbe, how = 'left', on = ['Cust_Id', 'Movie_Id']).fillna({'test':False}).infer_objects(copy=False)\n",
    "print(f\"the percentage of testing dataset is: {dfRating['test'].sum() / dfRating.shape[0]:.2%}\")\n",
    "\n",
    "# dfTitle = pd.read_csv('./netflix-prize-data/movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'], on_bad_lines='skip')\n",
    "# dfTitle.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c064c75",
   "metadata": {},
   "source": [
    "## Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_count = dfRating['Movie_Id'].nunique()\n",
    "cust_count = dfRating['Cust_Id'].nunique()\n",
    "rating_count = len(dfRating['Rating'])\n",
    "print(f\"movie_cout {movie_count:,}, cust_count {cust_count:,} rating_count {rating_count:,}\")\n",
    "print(f\"movie-user-matrix size = {movie_count * cust_count:,} number of non-zero entries {rating_count:,}, percentage of non-zero {rating_count / (movie_count * cust_count):.2%}\")\n",
    "print(f\"rating mean {dfRating['Rating'].mean():.2f}, rating std {dfRating['Rating'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c58ca",
   "metadata": {},
   "source": [
    "## Data Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894670e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSelect(dfData, pct):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    customers = list(dfData['Cust_Id'].unique())\n",
    "    movies = list(dfData['Movie_Id'].unique())\n",
    "    random_customers = random.sample(customers, round(len(customers) * pct))\n",
    "    random_movies = random.sample(movies, round(len(movies) * pct))\n",
    "    isSelected = dfData['Cust_Id'].isin(random_customers) & dfData['Movie_Id'].isin(random_movies)\n",
    "    return dfData[isSelected].copy(),dfData[~isSelected].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f47d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into kept data df and dropped data df1\n",
    "option = 2\n",
    "\n",
    "if option == 1: ### 1, no trimming\n",
    "    df = dfRating.copy()\n",
    "    df1 = pd.DataFrame()\n",
    "elif option == 2: ### 2, trim user or movie with little data, the assumption here is that user or movie with little data is with low qaulity and we drop them\n",
    "    measures = ['count', 'mean']\n",
    "    targePct = 0.7\n",
    "    df = dfRating.copy()\n",
    "    df[['Cust_Id', 'Movie_Id']] = df[['Cust_Id', 'Movie_Id']].astype(int)\n",
    "    df_movie_summary = df.groupby(['Movie_Id'])['Rating'].agg(measures)\n",
    "    movie_cutoff = round(df_movie_summary['count'].quantile(targePct), 0)\n",
    "    movie_to_drop = df_movie_summary[df_movie_summary['count'] < movie_cutoff].index\n",
    "    print(f\"movie_cutoff {movie_cutoff}, percentage of row to drop {len(movie_to_drop) / df_movie_summary.shape[0]:.2%}\")\n",
    "    df_cust_summary = df.groupby(['Cust_Id'])['Rating'].agg(measures)\n",
    "    cust_cutoff = round(df_cust_summary['count'].quantile(targePct), 0)\n",
    "    cust_to_drop = df_cust_summary[df_cust_summary['count'] < cust_cutoff].index\n",
    "    print(f\"cust_cutoff {cust_cutoff}, percentage of column to drop {len(cust_to_drop) / df_cust_summary.shape[0]:.2%}\")\n",
    "    df = df[(~df['Movie_Id'].isin(movie_to_drop)) & (~df['Cust_Id'].isin(cust_to_drop))]\n",
    "    df1 = dfRating[(dfRating['Movie_Id'].isin(movie_to_drop)) | (dfRating['Cust_Id'].isin(cust_to_drop))]\n",
    "    print(f\"Percentage of data keept = {df.shape[0]/dfRating.shape[0]:.2%}\")\n",
    "elif option == 3: ### 3, randomly trim, useful for debugging purpose\n",
    "    pct1 = 0.1\n",
    "    df,df1 = randomSelect(dfRating, pct1)\n",
    "    print(f\"number of customers {len(df['Cust_Id'].unique())}, number of movies {len(df['Movie_Id'].unique())}\")\n",
    "\n",
    "\n",
    "# split the data (df, df1) into training and testing based on column of \"test\"\n",
    "dfTrain = df[df['test'] == False]\n",
    "dfTest = df[df['test'] == True]\n",
    "\n",
    "df1Train = df1[df1['test'] == False]\n",
    "df1Test = df1[df1['test'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe3ee46",
   "metadata": {},
   "source": [
    "## SVD from suprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ded81",
   "metadata": {},
   "source": [
    "### Convert the dataframe to surprise format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c608dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "def convertDf2SurpriseData(dfTest, dfTrain):\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(dfTrain[['Cust_Id', 'Movie_Id', 'Rating']], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    testset = list(dfTest[['Cust_Id', 'Movie_Id', 'Rating']].itertuples(index=False, name=None))\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eeee310",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = convertDf2SurpriseData(dfTest, dfTrain)\n",
    "trainset1, testset1 = convertDf2SurpriseData(df1Test, df1Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9015c3",
   "metadata": {},
   "source": [
    "### SVD with different model dimension n_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "281863e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train the SVD model with n_factors = 25, 50, 100, record the training RMSE and testing RMSE\n",
    "run = False\n",
    "if ResourceWarning:\n",
    "    n_factors = [25, 50, 100]\n",
    "    train_rmse = []\n",
    "    test_rmse = []\n",
    "\n",
    "    for n in n_factors:\n",
    "        algo = SVD(n_factors = n)\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        train_rmse.append(accuracy.rmse(algo.test(trainset.build_testset())))\n",
    "        test_rmse.append(accuracy.rmse(predictions))\n",
    "\n",
    "## output\n",
    "# n_factor\ttraining rmse\ttesting rmse\n",
    "# 25\t0.8208\t1.0032\n",
    "# 50\t0.7977\t1.0047\n",
    "# 100\t0.7664\t1.0073\n",
    "# each takes about 25 mins to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076cc6d",
   "metadata": {},
   "source": [
    "From the output, testing RMSE is much worse than the training RMSE, indicating there is probability of overfitting, so we need try to tune the regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908694c1",
   "metadata": {},
   "source": [
    "### SVD with different regularization parameter reg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c35b8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train the SVD model with different regularization parameter, record the testing RMSE\n",
    "run = False\n",
    "if run:\n",
    "    reg_all = [0.001, 0.005, 0.01, 0.02]\n",
    "    test_rmse = []\n",
    "    for reg in reg_all:\n",
    "        print(f\"reg_all = {reg}\")\n",
    "        algo = SVD(reg_all = reg)\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        test_rmse.append(accuracy.rmse(predictions))\n",
    "\n",
    "## output\n",
    "# reg_all = 0.001\n",
    "# RMSE: 1.1043\n",
    "# reg_all = 0.005\n",
    "# RMSE: 1.0545\n",
    "# reg_all = 0.01\n",
    "# RMSE: 1.0279\n",
    "# reg_all = 0.02\n",
    "# RMSE: 1.0066\n",
    "# reg_all = 0.05\n",
    "# RMSE: 1.0075"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4f60f",
   "metadata": {},
   "source": [
    "The RMSE is minized when reg_all = 0.02, we will keep using this value.  But the testing RMSE is still very big compare to winning algorithm (~0.85), we still have a lot of room to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6fbfd8",
   "metadata": {},
   "source": [
    "### SVD with sparse data trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we have two sets of data, one is kept data, the other is dropped data.  We train the model with both data and compare the testing RMSE\n",
    "run = True\n",
    "if run:\n",
    "    algo = SVD(n_factors = 100, reg_all = 0.02)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    print(f\"the RMSE for testset is {accuracy.rmse(predictions):.2f}\")\n",
    "\n",
    "    algo1 = SVD(n_factors = 100, reg_all = 0.02)\n",
    "    algo1.fit(trainset1)\n",
    "    predictions1 = algo1.test(testset1)\n",
    "    print(f\"the RMSE for testset1 is {accuracy.rmse(predictions1):.2f}\")\n",
    "\n",
    "\n",
    "# output\n",
    "# RMSE for testset is 0.87\n",
    "# RMSE for testset1 is 1.06\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f6d7f",
   "metadata": {},
   "source": [
    "As we can see here, the performance for kept data (movies and users with enough ratings) is much better than dropped data (movies and users with sparse ratings).  This indicates the collaborative filtering (CF) perform better on movies and users with enough ratings.  Now let's dig into the two data sets to see if we can find anything that leads to this performance difference.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f364c",
   "metadata": {},
   "source": [
    "First, we see the standard deviation of dropped data is 1.14, comparing with 1.06 for the kept data. This means the dropped data is noisier thus harder to predict than kept data.  This agrees with my intuition, i.e. the movies or users with more ratings are easier to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of rating for df and df1 with plotly\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Histogram(x = df['Rating'], name = 'df', histnorm='probability', nbinsx = 5))\n",
    "# fig.add_trace(go.Histogram(x = df1['Rating'], name = 'df1', histnorm='probability', nbinsx = 5))\n",
    "# fig.show()\n",
    "\n",
    "# print(f\"df rating mean {df['Rating'].mean():.2f}, rating std {df['Rating'].std():.2f}\")\n",
    "# print(f\"df1 rating mean {df1['Rating'].mean():.2f}, rating std {df1['Rating'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46944881",
   "metadata": {},
   "source": [
    "### SVD++ with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edaf101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the SVDpp model with the data and calculate the RMSE for testing dataset\n",
    "from surprise import SVDpp\n",
    "algo = SVDpp(n_factors = 100, reg_all = 0.02)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "# output: takes about 55 mins to run\n",
    "# RMSE: 1.0201\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115474ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bce133e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we fit the df data with surprise SVD model without any special handling, it takes about 5 mins to run one training file,  the RMSE is 0.9025, which is not too good given the rating std is 1.086\n",
    "\n",
    "df = dfRating.copy()\n",
    "\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"RMSE on the test set is \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480f2d85",
   "metadata": {},
   "source": [
    "### SVD with trimmed data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1388ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the user or item with few interactions, it takes about 8 mins to run one training file, the RMSE is 0.8516\n",
    "measures = ['count', 'mean']\n",
    "targePct = 0.7\n",
    "df = dfRating.copy()\n",
    "df[['Cust_Id', 'Movie_Id']] = df[['Cust_Id', 'Movie_Id']].astype(int)\n",
    "df_movie_summary = df.groupby(['Movie_Id'])['Rating'].agg(measures)\n",
    "movie_cutoff = round(df_movie_summary['count'].quantile(targePct), 0)\n",
    "movie_to_drop = df_movie_summary[df_movie_summary['count'] < movie_cutoff].index\n",
    "print(f\"movie_cutoff {movie_cutoff}, percentage of row to drop {len(movie_to_drop) / df_movie_summary.shape[0]:.2%}\")\n",
    "df_cust_summary = df.groupby(['Cust_Id'])['Rating'].agg(measures)\n",
    "cust_cutoff = round(df_cust_summary['count'].quantile(targePct), 0)\n",
    "cust_to_drop = df_cust_summary[df_cust_summary['count'] < cust_cutoff].index\n",
    "print(f\"cust_cutoff {cust_cutoff}, percentage of column to drop {len(cust_to_drop) / df_cust_summary.shape[0]:.2%}\")\n",
    "df = df[(~df['Movie_Id'].isin(movie_to_drop)) & (~df['Cust_Id'].isin(cust_to_drop))]\n",
    "print(f\"Percentage of data keept = {df.shape[0]/dfRating.shape[0]:.2%}\")\n",
    "\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "predictions = svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"RMSE on the test set is \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a3e26",
   "metadata": {},
   "source": [
    "# SVD from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SVD from SKLearn library, train the model with the training data, and calculate the root mean square error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "n_components = 100\n",
    "\n",
    "# train the SVD model\n",
    "df = dfTrain.copy()\n",
    "row_ind, col_ind, data = np.array(df['Cust_Id']), np.array(df['Movie_Id']), np.array(df['Rating'])\n",
    "matrix = csr_matrix((data, (row_ind, col_ind)), shape = (max(row_ind) + 1, max(col_ind) + 1)) # sparse matrix\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "svd.fit(matrix)\n",
    "\n",
    "# test the SVD model\n",
    "df = dfTest.copy()\n",
    "row_ind, col_ind, data = np.array(df['Cust_Id']), np.array(df['Movie_Id']), np.array(df['Rating'])\n",
    "matrix_test = csr_matrix((data, (row_ind, col_ind)), shape = (max(row_ind) + 1, max(col_ind) + 1)) # sparse matrix\n",
    "matrix_transformed = svd.transform(matrix_test)\n",
    "matrix_reconstructed = svd.inverse_transform(matrix_transformed)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(matrix_test.toarray(), matrix_reconstructed))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "#print(svd.explained_variance_ratio_)\n",
    "#print(svd.explained_variance_ratio_.sum())\n",
    "#print(svd.singular_values_)\n",
    "\n",
    "# components = [i+1 for i in range(n_components)]\n",
    "# fig = px.line(x=components, y=svd.explained_variance_ratio_.cumsum())\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# matrix_reconstructed = svd.inverse_transform(matrix_transformed)\n",
    "# rmse = np.sqrt(mean_squared_error(matrix, matrix_reconstructed))\n",
    "# print(f\"Training RMSE: {rmse:.4f}\")\n",
    "\n",
    "\n",
    "# calculate the RMSE on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89f7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
